# ğŸš€ IT Operations Analytics: De Datos Crudos a Estrategia con IA

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Pandas](https://img.shields.io/badge/Pandas-Data%20Analysis-orange)
![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-Machine%20Learning-red)
![Status](https://img.shields.io/badge/Status-Completed-success)

## ğŸ“‹ DescripciÃ³n del Proyecto

En el ecosistema empresarial actual, los departamentos de TI generan miles de registros de incidencias que a menudo se infrautilizan. Este proyecto simula un caso real de consultorÃ­a de datos, cuyo objetivo es **transformar logs operativos planos en un Plan EstratÃ©gico de Negocio**.

A travÃ©s de un ciclo completo de Data Science, el proyecto audita la eficiencia del servicio, detecta riesgos de capital humano (burnout) y aplica algoritmos de **Machine Learning (K-Means y Random Forest)** para segmentar incidencias y predecir cargas de trabajo.

## ğŸ¯ Objetivos de Negocio Resueltos

El anÃ¡lisis responde a preguntas crÃ­ticas para la direcciÃ³n:
1.  **Eficiencia Operativa:** Â¿DÃ³nde estÃ¡n los cuellos de botella y los "agujeros negros" de productividad?
2.  **Sostenibilidad del Equipo:** Â¿Existe riesgo de fuga de talento o dependencia crÃ­tica de una sola persona ("Bus Factor")?
3.  **Calidad del Servicio:** Â¿Estamos resolviendo los problemas de raÃ­z o solo poniendo parches (incidencias zombie)?
4.  **OptimizaciÃ³n de Costes:** Â¿QuÃ© incidencias deberÃ­amos automatizar con Chatbots/RPA?

## ğŸ› ï¸ Stack TecnolÃ³gico

* **IngenierÃ­a de Datos:** `Pandas`, `NumPy` (Limpieza robusta, manejo de encoding `latin1`/`utf-8`, ingenierÃ­a de variables temporales).
* **VisualizaciÃ³n:** `Seaborn`, `Matplotlib` (Heatmaps, Diagramas de Pareto, Violines, Scatter Plots).
* **Machine Learning:**
    * **Scikit-Learn:** Clustering K-Means (SegmentaciÃ³n no supervisada), Random Forest (SimulaciÃ³n de escenarios).
    * **Statsmodels:** Holtâ€™s Exponential Smoothing (Forecasting de demanda temporal).

## ğŸ“Š Estructura del AnÃ¡lisis

El notebook sigue una narrativa de negocio estructurada en 5 fases:

1.  **ğŸ›¡ï¸ Data Quality & Ingesta:** Pipeline de carga "fail-safe" y normalizaciÃ³n de esquemas.
2.  **ğŸ“ˆ Business Intelligence (BI):**
    * Ley de Pareto (80/20) en solicitantes.
    * Matriz de DesempeÃ±o TÃ©cnico (Velocidad vs. Volumen).
3.  **âš ï¸ AuditorÃ­a de Riesgos (RRHH):**
    * CÃ¡lculo de "Carga Oculta" (Trabajo fuera de horario).
    * DetecciÃ³n del "Bus Factor" (Dependencia crÃ­tica de un tÃ©cnico).
4.  **ğŸ“‰ Calidad y RetenciÃ³n:**
    * AnÃ¡lisis de Recidiva (Problemas Zombie).
    * Riesgo de Fuga de Clientes (Churn Risk por Recencia).
5.  **ğŸ¤– Advanced Analytics & AI:**
    * **SegmentaciÃ³n K-Means:** Descubrimiento de 3 clusters operativos (Quick Wins, Proyectos, Bloqueos).
    * **Scorecard Ejecutivo:** GeneraciÃ³n automÃ¡tica de recomendaciones estratÃ©gicas.

## ğŸ’¡ Insights Clave (Resultados)

Tras el anÃ¡lisis, se obtuvieron las siguientes conclusiones estratÃ©gicas:

* **Riesgo CrÃ­tico:** Se detectÃ³ una dependencia del **30%** en un Ãºnico tÃ©cnico, lo que representa un riesgo operativo inaceptable.
* **Oportunidad de Ahorro:** El algoritmo K-Means identificÃ³ un cluster de "Quick Wins" (alto volumen, baja complejidad) ideal para ser automatizado, liberando un **20% de la carga de trabajo**.
* **Ineficiencia de Procesos:** Se identificaron cuellos de botella administrativos donde los tickets pasan semanas abiertos con menos de 1 hora de trabajo real.

## ğŸš€ CÃ³mo ejecutar este proyecto

1.  Clonar el repositorio:
    ```bash
    git clone [https://github.com/TU_USUARIO/IT-Operations-Analytics.git](https://github.com/TU_USUARIO/IT-Operations-Analytics.git)
    ```
2.  Instalar dependencias:
    ```bash
    pip install -r requirements.txt
    ```
3.  Ejecutar el notebook `AnÃ¡lisis.ipynb` en Jupyter Lab, VS Code o Google Colab.

---
*Portfolio de Data Science & Operations Analytics*
